<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>MALib | A parallel framework for population-based multi-agent reinforcement learning.</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="MALib" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A parallel framework for population-based multi-agent reinforcement learning." />
<meta property="og:description" content="A parallel framework for population-based multi-agent reinforcement learning." />
<meta property="og:site_name" content="MALib" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="MALib" />
<script type="application/ld+json">
{"description":"A parallel framework for population-based multi-agent reinforcement learning.","headline":"MALib","url":"/","@type":"WebSite","name":"MALib","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="MALib" /></head>
<body><header class="site-header" role="banner">
    
    <div class="wrapper"><a class="site-title" rel="author" href="/">MALib</a>
      
      <!-- <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>
        <a class="page-link" href="https://github.com/sjtu-marl/malib">
            <img
            src="../images/github.svg"
            alt="Fork me on GitHub">
        </a>
        <a class="page-link" href=""> 123 </a>
    </nav> -->
      

        <nav class="site-nav">
            <input type="checkbox" id="nav-trigger" class="nav-trigger" />
            <label for="nav-trigger">
            <span class="menu-icon">
                <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                </svg>
            </span>
            </label>
            
            <div class="trigger">
                <a class="page-link" href="https://github.com/sjtu-marl/malib">
                    <img
                    src="../images/github.svg"
                    alt="Fork me on GitHub">
                </a></div>
        </nav>

    </div>
  </header>
  <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><div align="center" style="margin-bottom: 20px"><img src="docs/imgs/logo.svg" width="35%" /></div>

<h1 id="malib-a-parallel-framework-for-population-based-multi-agent-reinforcement-learning">MALib: A parallel framework for population-based multi-agent reinforcement learning</h1>

<p><a href="https://github.com/sjtu-marl/malib/blob/main/LICENSE"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="GitHub license" /></a>
<a href="https://malib.readthedocs.io/en/latest/?badge=latest"><img src="https://readthedocs.org/projects/malib/badge/?version=latest" alt="Documentation Status" /></a></p>

<p>MALib is a parallel framework of population-based learning nested with (multi-agent) reinforcement learning (RL) methods, such as Policy Space Response Oracle, Self-Play and Neural Fictitous Self-Play. MALib provides higher-level abstractions of MARL training paradigms, which enables efficient code reuse and flexible deployments on different distributed computing paradigms. The design of MALib also strives to promto the research of other multi-agent learning, including multi-agent imitation learning and model-based MARL.</p>

<p><img src="docs/imgs/Architecture.svg" alt="architecture" /></p>

<h2 id="installation">Installation</h2>

<p>The installation of MALib is very easy. Weâ€™ve tested MALib on Python 3.6 and 3.7. This guide is based on ubuntu 18.04 and above. We strongly recommend using <a href="https://docs.conda.io/en/latest/miniconda.html">conda</a> to manage your dependencies, and avoid version conflicts. Here we show the example of building python 3.7 based conda environment.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">-n</span> malib <span class="nv">python</span><span class="o">==</span>3.7 <span class="nt">-y</span>
conda activate malib

<span class="c"># install dependencies</span>
./install_deps.sh

<span class="c"># install malib</span>
pip <span class="nb">install</span> <span class="nt">-e</span> <span class="nb">.</span>
</code></pre></div></div>

<p>External environments are integrated in MALib, such as StarCraftII and vizdoom, you can install them via <code class="language-plaintext highlighter-rouge">pip install -e .[envs]</code>. For users who wanna contribute to our repository, run <code class="language-plaintext highlighter-rouge">pip install -e .[dev]</code> to complete the development dependencies.</p>

<p><strong>optional</strong>: if you wanna use alpha-rank to solve meta-game, install open-spiel with its <a href="https://github.com/deepmind/open_spiel">installation guides</a></p>

<h2 id="quick-start">Quick Start</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""PSRO with PPO for Leduc Holdem"""</span>

<span class="kn">from</span> <span class="nn">malib.envs.poker</span> <span class="kn">import</span> <span class="n">poker_aec_env</span> <span class="k">as</span> <span class="n">leduc_holdem</span>
<span class="kn">from</span> <span class="nn">malib.runner</span> <span class="kn">import</span> <span class="n">run</span>
<span class="kn">from</span> <span class="nn">malib.rollout</span> <span class="kn">import</span> <span class="n">rollout_func</span>


<span class="n">env</span> <span class="o">=</span> <span class="n">leduc_holdem</span><span class="p">.</span><span class="n">env</span><span class="p">(</span><span class="n">fixed_player</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">run</span><span class="p">(</span>
    <span class="n">agent_mapping_func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">agent_id</span><span class="p">:</span> <span class="n">agent_id</span><span class="p">,</span>
    <span class="n">env_description</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"creator"</span><span class="p">:</span> <span class="n">leduc_holdem</span><span class="p">.</span><span class="n">env</span><span class="p">,</span>
        <span class="s">"config"</span><span class="p">:</span> <span class="p">{</span><span class="s">"fixed_player"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
        <span class="s">"id"</span><span class="p">:</span> <span class="s">"leduc_holdem"</span><span class="p">,</span>
        <span class="s">"possible_agents"</span><span class="p">:</span> <span class="n">env</span><span class="p">.</span><span class="n">possible_agents</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">training</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"interface"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"type"</span><span class="p">:</span> <span class="s">"independent"</span><span class="p">,</span>
            <span class="s">"observation_spaces"</span><span class="p">:</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_spaces</span><span class="p">,</span>
            <span class="s">"action_spaces"</span><span class="p">:</span> <span class="n">env</span><span class="p">.</span><span class="n">action_spaces</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="n">algorithms</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"PSRO_PPO"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"name"</span><span class="p">:</span> <span class="s">"PPO"</span><span class="p">,</span>
            <span class="s">"custom_config"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">"gamma"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s">"eps_min"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s">"eps_max"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
                <span class="s">"eps_decay"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="p">},</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="n">rollout</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"type"</span><span class="p">:</span> <span class="s">"async"</span><span class="p">,</span>
        <span class="s">"stopper"</span><span class="p">:</span> <span class="s">"simple_rollout"</span><span class="p">,</span>
        <span class="s">"callback"</span><span class="p">:</span> <span class="n">rollout_func</span><span class="p">.</span><span class="n">sequential</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="documentation">Documentation</h2>

<p>See <a href="https://malib.readthedocs.io/">MALib Docs</a></p>

<h2 id="citing-malib">Citing MALib</h2>

<p>If you use MALib in your work, please cite the accompanying <a href="https://yingwen.io/malib.pdf">paper</a>.</p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhou2021malib</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{MALib: A Parallel Framework for Population-based Multi-agent Reinforcement Learning}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Zhou, Ming and Wan, Ziyu and Wang, Hanjing and Wen, Muning and Wu, Runzhe and Wen, Ying and Yang, Yaodong and Zhang, Weinan and Wang, Jun}</span><span class="p">,</span>
    <span class="na">booktitle</span><span class="p">=</span><span class="s">{Preprint}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
    <span class="na">organization</span><span class="p">=</span><span class="s">{Preprint}</span>
<span class="p">}</span>
</code></pre></div></div>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">MALib</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">MALib</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/sjtu-marl"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">sjtu-marl</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A parallel framework for population-based multi-agent reinforcement learning.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
