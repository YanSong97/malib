group: "MPE"
name: "psro/ppo"

training:
  interface:
    type: "independent"
    population_size: -1
  config:
    # control the frequency of remote parameter update
    update_interval: 1
    saving_interval: 10
    batch_size: 1024
    optimizer: "adam"
    actor_lr: !!float 1e-2
    critic_lr: !!float 1e-2
    tau: 0.01  # soft update
    grad_norm_clipping: 0.5

rollout:
  type: "async"
  stopper: "simple_rollout"
  stopper_config:
    max_step: 1000
  metric_type: "simple"
  fragment_length: 1000
  num_episodes: 1000
  episode_seg: 100
  terminate: "any"
  callback: "sequential"

env_description:
  id: "simple_push_v2"
  config:
    max_cycles: 25

algorithms:
  PPO:
    name: "PPO"
    model_config:
      actor:
        network: mlp
        layers:
          - units: 64
            activation: ReLU
          - units: 64
            activation: ReLU
        output:
          activation: False
      critic:
        network: mlp
        layers:
          - units: 64
            activation: ReLU
          - units: 64
            activation: ReLU
        output:
          activation: False

    # set hyper parameter
    custom_config:
      gamma: 0.95
      use_cuda: False  # enable cuda or not

global_evaluator:
  name: "psro"

dataset_config:
  episode_capacity: 1000000
