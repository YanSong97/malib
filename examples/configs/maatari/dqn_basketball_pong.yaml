group: "maatari/basketball"
name: "dqn_shared"

training:
  interface:
    type: independent
    population_size: -1
    use_init_population_pool: False
  config:
    update_interval: 5
    batch_size: 128

rollout_worker:
  callback: simultaneous
  stopper:
    name: simple_rollout
    config:
      max_step: 1250
  num_threads: 2
  num_env_per_thread: 2
  num_eval_threads: 5
  batch_mode: time_step
  post_processor_types:
    - default
  use_subproc_env: False
  task_config:
    max_step: 100
    fragment_length: 200

evaluation:
  fragment_length: 200
  num_episodes: 1

env_description:
  creator: MAAtari
  config:
    env_id: "basketball_pong_v2"
    # supersuit wrapper
    # see: https://github.com/PettingZoo-Team/SuperSuit
    scenario_configs:
      obs_type: "grayscale_image"
      num_players: 2
    wrappers:
      # resize_v0: downscale observation for faster processing
      # max_observation_v0: as per openai baseline's MaxAndSKip wrapper, maxes over the last {param} frames
      #   to deal with frame flickering
      # sticky_actions_v0: repeat_action_probability is set to {param} to introduce non-determinism to the system
      - name: "resize_v0"
        params:
          - 84
          - 84
      - name: "dtype_v0"
        params:
          - "float32"
      - name: "normalize_obs_v0"
        params:
          env_min: 0.
          env_max: 1.
      # must be either 2 or 4

algorithms:
  DQN:
    name: "DQN"
    custom_config:
      gamma: 0.98
      eps_max: 1.0
      eps_min: 0.1
      eps_anneal_time: 10000

global_evaluator:
  name: "generic"

dataset_config:
  episode_capacity: 10000